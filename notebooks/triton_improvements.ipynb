{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d919f269-2d11-4d26-9f60-6ba9a56f32c3",
   "metadata": {},
   "source": [
    "# RWKV 6.X to Triton Port\n",
    "\n",
    "This notebook is designeed to help while porting RWKV6+ to triton. It first validates the algorithm in torch before porting to triton. Testbed for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9bb6d1-6db4-4188-b477-76df527fbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e5606-84d7-4857-bbee-bb7bfaf15363",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5be6d20-c942-4ed7-8471-3bbc238157ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_inputs(B, H, L, K, V): \n",
    "    th.manual_seed(17)\n",
    "    device = \"cpu\"\n",
    "    rt = th.randn(B, H, L, K, device=device, requires_grad=True)\n",
    "    kt = th.randn(B, H, L, K, device=device, requires_grad=True)\n",
    "    vt = th.randn(B, H, L, V, device=device, requires_grad=True)\n",
    "    wt = th.randn(B, H, L, K, V, device=device, requires_grad=True)\n",
    "    ut = th.randn(H, K, device=device, requires_grad=True)\n",
    "    return rt, kt, vt, wt, ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df5bf84-55b6-446f-b02a-d6a7166e194b",
   "metadata": {},
   "source": [
    "## Diagnosis of 18/04/2024\n",
    "* [ ] [Songlin's code](https://github.com/sustcsonglin/flash-linear-attention/commit/fee90b2e72366a46c60e3ef16431133aa5aced8d) is wrong for the backward pass of `W`. Although it is hidden for normally-distributed values and high number of `V`. \n",
    "* [ ] TODO: extend U and W to support matrices. Experiments demonstrate it works wonders. Especially later in training.\n",
    "    * [This paper: The illusion of State in State Space Models](https://arxiv.org/pdf/2404.08819.pdf) demonstrates that a `matrix_cumprod` would give superior modelling ability. The matrix has to be non-diagonal as otherwise it would be a `cum_matmul` which would still be in `TC0` and not `NC1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1919e1bd-12f2-4121-b10a-e1768cb311b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### rwkv_inner (from gptcore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae7e0be-b740-4d83-b371-4daeda7b6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def rwkv_inner(r,k,v,w,u,kv_state,chunk_len:int=24,precision_dtype:th.dtype=th.float32):\n",
    "    \"\"\"\n",
    "    expects\n",
    "    r : (B,H,L,K)\n",
    "    k : (B,H,L,K)\n",
    "    v : (B,H,L,V)\n",
    "    w : (B,H,L,K) or (1,H,L,K)\n",
    "    u : (1,H,1,K)\n",
    "    kv_state : (B,H,K,V)\n",
    "    \"\"\"\n",
    "    B,H,L,K = k.size()\n",
    "    V = v.size(-1)\n",
    "    T = chunk_len\n",
    "\n",
    "    if L == 1:\n",
    "        kv = k.mT @ v\n",
    "        out = r @ (kv_state + u.mT * kv)\n",
    "        kv_state = w.mT * kv_state + kv\n",
    "        return out, kv_state\n",
    "    else:\n",
    "        # FIXME - support fast path for non-exact multiples\n",
    "        # ensure it's an exact multiple\n",
    "        if L % T != 0:\n",
    "            T = 1\n",
    "\n",
    "        N = L // T\n",
    "\n",
    "        # this has to be done to avoid numerical instability (inf/NaN) when w is used as a divisor up to chunk_length//2 places away (so precision_min_val^(T//2) has to be in fp range)\n",
    "        # NOTE - this does not account for the impact of the size of R, K so we currently use the chunk_len=32 numbers for chunk_len=24\n",
    "        assert(precision_dtype == th.float32 or precision_dtype == th.float64)\n",
    "        if precision_dtype == th.float32:\n",
    "            precision_min_val = 0.005 # good for fp32 (1.175e-38 ^ (1/16.0) < 0.00426)\n",
    "        else: #elif precision_dtype == torch.float64:\n",
    "            precision_min_val = 1e-10 # good for fp64 (1.7e-308 ^ (1/16.0) < 5.8e-20)\n",
    "        w = w.clamp(precision_min_val)\n",
    "\n",
    "        # calculate cumulative decay in log space where it won't overflow\n",
    "        w_log = w.float().log() # (1,H,L,K) or (B,H,L,K)\n",
    "\n",
    "        # chunked view of w_log\n",
    "        wc_log = w_log.view(w.size(0),H,N,T,K)\n",
    "        wc_log_cum = wc_log.cumsum(dim=-2)\n",
    "\n",
    "        # chunked view of shifted_w_log\n",
    "        shifted_wc_log_cum = F.pad(wc_log_cum, (0, 0, 1, -1))\n",
    "\n",
    "\n",
    "        # NOTE - we have to apply the decay weight from TWO ahead.. ONE ahead gets no decay (log==0)\n",
    "        # pre-applied weights\n",
    "        # left side is prior chunk (w_inter), right side is current chunk (w_intra)\n",
    "        # without u...\n",
    "        # w0   w1   w2   w3   | w4   w5   w6   w7          \n",
    "        # w1:4 w2:4 w3:4 w4:4 | w4:5 w4:6 w4:7 w4:8\n",
    "        # with u...\n",
    "        # w0   w1   w2   w3   | w4   w5   w6   w7          \n",
    "        # w1:4 w2:4 w3:4 w4:4 | w4:4 w4:5 w4:6 w4:7\n",
    "\n",
    "        # ws decays the entire current state (representing t-1) to the prior block (t-2)\n",
    "        ws = wc_log.sum(dim=-2, keepdim=True) # 1HN1K or BHN1K\n",
    "        # w_inter is the decay to the end of the current block, since it will be applied at the next iteration when current (t) becomes prior (t-1)\n",
    "        # this formula because e.g. w1:4 = w0:4 - w0:1\n",
    "        w_inter = ws - wc_log_cum # 1HNTK or BHNTK (w^(T-1) ... w^0)\n",
    "        # w_intra is the decay from the beginning of the current block (t), since it will be applied to current queries (t) against prior state (representing keys+values up to but not including block t)\n",
    "        # this formula because e.g. w1:3 = w0:3 - w0\n",
    "        w_intra = wc_log_cum - wc_log # 1HNTK or BHNTK (w^0 ... w^(T-2))\n",
    "\n",
    "        ws = list(ws.mT.exp().to(r.dtype).unbind(dim=-3)) # N x 1HK1 or BHK1 !!NOTE THE .mT HERE!!\n",
    "        w_inter = w_inter.exp().to(r.dtype) # 1HNTK or BHNTK\n",
    "        w_intra = w_intra.exp().to(r.dtype) # 1HNTK or BHNTK\n",
    "\n",
    "        # chunked view of r, k, v\n",
    "        r = r.view(B,H,N,T,K) \n",
    "        k = k.view(B,H,N,T,K) \n",
    "        v = v.view(B,H,N,T,V)\n",
    "        u = u.unsqueeze(2).to(r.dtype) # (1,H,1,1,K)\n",
    "\n",
    "        # parallel calculation of all intra-chunk attention contributions\n",
    "        wc_log_offset = shifted_wc_log_cum[...,T//2:T//2+1,:] # B,H,N,1,K\n",
    "        r_decay = (shifted_wc_log_cum - wc_log_offset).to(precision_dtype).exp() # B,H,N,T,K\n",
    "        k_inv_decay = (wc_log_offset - wc_log_cum).to(precision_dtype).exp() # B,H,N,T,K\n",
    "        a = ((r*r_decay) @ (k*k_inv_decay).mT).to(r.dtype).tril(-1) # B,H,N,T,T\n",
    "        # add u term to attention (NOTE - the tril(-1) above zeroed the diagonal)\n",
    "        a = a + th.einsum('bhntk,bhntk->bhnt', r, u * k).diag_embed()\n",
    "        out = a @ v # BHNTV\n",
    "        # alternate way of adding in u\n",
    "        # out = out + torch.einsum('bhntk,bhntk,bhntv->bhntv', r, u * k, v) \n",
    "\n",
    "        # parallel precalculation of chunked (k*wk).mT@v for use in recurrent state calc below\n",
    "        wkv = (k * w_inter).mT @ v # BHNKV\n",
    "        wkv = list(wkv.unbind(dim=-3)) # N x BHKV\n",
    "\n",
    "        # recurrent calculation of all states\n",
    "        states = []\n",
    "        for i in range(N):\n",
    "            states.append(kv_state)\n",
    "            kv_state = kv_state * ws[i] + wkv[i] # BHKV\n",
    "            # equivalent non-precalced version\n",
    "            #wkv = (k[...,i,:,:] * wk[...,i,:,:]).mT @ v[...,i,:,:]\n",
    "            #kv_state = kv_state * ws[i] + wkv\n",
    "        states = th.stack(states, dim=2) # BHNKV       \n",
    "\n",
    "        # parallel application of all r to states\n",
    "        out = out + (r * w_intra) @ states # BHNTV\n",
    "        out = out.view(B,H,L,V)\n",
    "        return out, kv_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e66818-cecf-49c9-b134-8e25d9a6f6ec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Base Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f533eb-caaa-45be-8568-9be6be86fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "\n",
    "def naive_recurrent_rwkv6_original(q, k, v, w, u, initial_state=None, output_final_state=False):\n",
    "    orig_dtype = q.dtype\n",
    "    q, k, v, w, u = map(lambda x: x.float(), (q, k, v, w, u))\n",
    "    batch_size, n_heads, seq_len, d_head_k = q.shape\n",
    "    _, _, _, d_head_v = v.shape\n",
    "    h = torch.zeros(batch_size, n_heads, d_head_k, d_head_v, dtype=torch.float32, device=q.device)\n",
    "    o = torch.zeros_like(v)\n",
    "\n",
    "    if initial_state is not None:\n",
    "        h += initial_state\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        q_i = q[:, :, i, :]\n",
    "        k_i = k[:, :, i]\n",
    "        v_i = v[:, :, i, :]\n",
    "        w_i = w[:, :, i].exp()\n",
    "        kv_i = k_i[..., None] * v_i[..., None, :]\n",
    "        o_i = (h + u[None, ..., None] * kv_i) * q_i[..., None]\n",
    "        o[:, :, i] = o_i.sum(-2)\n",
    "        h = h * w_i[..., None] + kv_i\n",
    "    return o.to(orig_dtype)\n",
    "\n",
    "\n",
    "def naive_recurrent_rwkv6_bwd_original(q, k, v, w, u, o, do, initial_state=None, output_final_state=False):\n",
    "    q, k, v, w, u, o, do = map(lambda x: x.float(), (q, k, v, w, u, o, do))\n",
    "    batch_size, n_heads, seq_len, d_head_k = q.shape\n",
    "    _, _, _, d_head_v = v.shape\n",
    "    h = torch.zeros(batch_size, n_heads, d_head_k, d_head_v, dtype=torch.float32, device=q.device)\n",
    "    dq = torch.zeros_like(q)\n",
    "    dq_aux = torch.zeros_like(q)\n",
    "\n",
    "    if initial_state is not None:\n",
    "        h += initial_state\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        k_i = k[:, :, i]\n",
    "        v_i = v[:, :, i]\n",
    "        w_i = w[:, :, i].exp()\n",
    "        kv_i = k_i[..., None] * v_i[..., None, :]\n",
    "        h_i = (h + u[None, ..., None] * kv_i)\n",
    "        dq_i = (do[:, :, i, None, :] * h_i).sum(-1)\n",
    "        dq_aux_i = (do[:, :, i, None, :] * h).sum(-1)\n",
    "        dq[:, :, i] = dq_i\n",
    "        dq_aux[:, :, i] = dq_aux_i\n",
    "        h = h * w_i[..., None] + kv_i\n",
    "\n",
    "    du = u.new_zeros(batch_size, n_heads, d_head_k)\n",
    "    dh = torch.zeros_like(h)\n",
    "    dk = torch.zeros_like(k)\n",
    "    dk_aux = torch.zeros_like(k)\n",
    "    dv = torch.zeros_like(v)\n",
    "\n",
    "    for i in range(seq_len-1, -1, -1):\n",
    "        d_kv_i = do[:, :, i, None, :] * q[:, :, i, :, None]\n",
    "        k_i = k[:, :, i]\n",
    "        v_i = v[:, :, i]\n",
    "        du_i = (d_kv_i * k_i[..., None] * v_i[..., None, :]).sum(-1)\n",
    "        du += du_i\n",
    "        dk_i = (dh * v_i[..., None, :]).sum(-1)\n",
    "        dk_aux[:, :, i] = dk_i\n",
    "        dk_i += (d_kv_i * u[None, ..., None] * v_i[..., None, :]).sum(-1)\n",
    "        dv_i = (d_kv_i * u[None, ..., None] * k_i[..., None]).sum(-2)\n",
    "        dv_i += (dh * k_i[..., None]).sum(-2)\n",
    "\n",
    "        dk[:, :, i] = dk_i\n",
    "        dv[:, :, i] = dv_i\n",
    "        dh = dh * w[:, :, i, :, None].exp() + d_kv_i\n",
    "\n",
    "    # dw = q * dq_aux - k * dk_aux\n",
    "    dw = torch.zeros_like(w)\n",
    "    for i in range(seq_len-2, -1, -1):\n",
    "        dw[:, :, i] = dw[:, :, i+1] + dq_aux[:, :, i+1] * q[:, :, i+1] - dk_aux[:, :, i] * k[:, :, i]\n",
    "\n",
    "    du = du.sum(0)\n",
    "    return dq, dk, dv, dw, du"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e42b78-67bb-4d70-bca8-388dd539a070",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Demonstrate Songlin's Code is Wrong: \n",
    "Songlin's code is wrong! Hidden by a high `|V|`\n",
    "\n",
    "* `V = 1` and errors era ~1e-2\n",
    "* `V = 64` and errors era ~1e-9\n",
    "\n",
    "`Autograd(recurrent_naive_fw)` and `rwkv_inner` match (0 error) but both disagree with `recurrent_naive_bw`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7298ecc-340f-451e-8d53-67b7c6148b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-5.4060e-09, -3.1498e-05, -1.1221e-04, -8.7801e-05,  1.5598e-03,\n",
       "         -9.9161e-03, -1.2344e-03, -8.6985e-03, -1.6997e-03, -8.5992e-04,\n",
       "          1.4172e-02, -1.1259e-05, -1.2936e-01, -4.7139e-02, -3.9083e-02,\n",
       "         -0.0000e+00]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([-5.4060e-09, -9.9698e-06, -3.1177e-05, -2.3574e-05,  3.9917e-04,\n",
       "         -4.3252e-03, -5.3626e-04, -3.3183e-03, -1.0520e-03, -2.2075e-04,\n",
       "          1.1902e-02, -9.0152e-07, -9.2706e-02, -1.5038e-02, -2.4199e-02,\n",
       "         -0.0000e+00]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementation is wrong. hidden by high V (ex. 64)\n",
    "B, H, L, K, V = 1, 1, 16, 1, 1\n",
    "\n",
    "#### AUTOGRAD FORWARD PASS\n",
    "rt, kt, vt, wt, ut = gen_inputs(B, H, L, K, V)\n",
    "w_ = -th.exp(wt)\n",
    "o = naive_recurrent_rwkv6_original(rt, kt, vt, w_[..., 0], ut[..., 0])\n",
    "grads = []\n",
    "o.register_hook(lambda d:grads.append(d))\n",
    "o.mean().backward()\n",
    "do = grads[0]\n",
    "\n",
    "#### Autograd rwkv_inner\n",
    "rt3, kt3, vt3, wt3, ut3 = gen_inputs(B, H, L, K, V)\n",
    "w3_ = -th.exp(wt3)\n",
    "o3, state3 = rwkv_inner(rt3, kt3, vt3, w3_[..., 0], ut3.view(1, H, 1, K), th.zeros(B, H, K, V))\n",
    "o3.mean().backward()\n",
    "\n",
    "#### MANUAL BACKWARD PASS\n",
    "rt2, kt2, vt2, wt2, ut2 = gen_inputs(B, H, L, K, V)\n",
    "w2_ = -th.exp(wt2)\n",
    "dq, dk, dv, dw, du = naive_recurrent_rwkv6_bwd_original(rt2, kt2, vt2, w2_[..., 0], ut2[..., 0], o, do)\n",
    "dw = dw[..., None]\n",
    "(wt.grad - dw).detach().flatten(), (w_ - w2_).detach().flatten(), (wt3.grad - dw).detach().flatten(), (w3_ - w2_).detach().flatten()\n",
    "\n",
    "#### DOESN'T MATCH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63430906-5a27-4f45-a755-721badae858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.4552e-09, -1.4552e-09, -1.4552e-09,  ..., -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]),\n",
       " tensor([-1.4552e-09, -1.4552e-09, -1.4552e-09,  ..., -0.0000e+00,\n",
       "         -0.0000e+00, -0.0000e+00]),\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementation is wrong. hidden by high V (ex. 64)\n",
    "B, H, L, K, V = 1, 1, 16, 1, 64\n",
    "\n",
    "#### AUTOGRAD FORWARD PASS\n",
    "rt, kt, vt, wt, ut = gen_inputs(B, H, L, K, V)\n",
    "w_ = -th.exp(wt)\n",
    "o = naive_recurrent_rwkv6_original(rt, kt, vt, w_[..., 0], ut[..., 0])\n",
    "grads = []\n",
    "o.register_hook(lambda d:grads.append(d))\n",
    "o.mean().backward()\n",
    "do = grads[0]\n",
    "\n",
    "#### Autograd rwkv_inner\n",
    "rt3, kt3, vt3, wt3, ut3 = gen_inputs(B, H, L, K, V)\n",
    "w3_ = -th.exp(wt3)\n",
    "o3, state3 = rwkv_inner(rt3, kt3, vt3, w3_[..., 0], ut3.view(1, H, 1, K), th.zeros(B, H, K, V))\n",
    "o3.mean().backward()\n",
    "\n",
    "#### MANUAL BACKWARD PASS\n",
    "rt2, kt2, vt2, wt2, ut2 = gen_inputs(B, H, L, K, V)\n",
    "w2_ = -th.exp(wt2)\n",
    "dq, dk, dv, dw, du = naive_recurrent_rwkv6_bwd_original(rt2, kt2, vt2, w2_[..., 0], ut2[..., 0], o, do)\n",
    "dw = dw[..., None]\n",
    "(wt.grad - dw).detach().flatten(), (w_ - w2_).detach().flatten(), (wt3.grad - dw).detach().flatten(), (w3_ - w2_).detach().flatten()\n",
    "\n",
    "#### DOESN'T MATCH!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6df76d4f-91f4-43c8-be24-4cf01163ef46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 16, 1, 1]), torch.Size([1, 1, 16, 1, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt.grad.shape, dw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8b7c2-bc11-4eb3-b23c-1011ed26bd6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Manual: Fixing backward implementation¶ - DISCARDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0160f72f-d91a-4c3a-86b7-32c1f86232be",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 4\n",
    "q_ic, k_jc, v_jd, w_tc_prelog, _ = gen_inputs(1, 1, L, 1, 1)\n",
    "w_tc = -th.exp(w_tc_prelog)\n",
    "\n",
    "q_ic, k_jc, v_jd, w_tc = map(lambda x: x[0, 0].detach.requires_grad(True), (q_ic, k_jc, v_jd, w_tc))\n",
    "\n",
    "wcum_jc_buffer = []\n",
    "for j in range(1, L+1): \n",
    "    wcum_jc_buffer.append( w_tc[:j].cumsum(dim=0).exp() )\n",
    "wcum_jc = th.stack(wcum_jc_buffer)\n",
    "        \n",
    "inner_jcd = th.einsum('jc,jc,jd->jcd', wcum_jc, k_jc, v_jd)\n",
    "wkv_icd = th.cumsum(inner_jcd, dim=0)\n",
    "oid = th.einsum('ic,icd->id', q_ic, wkv_icd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daec8c5b-61b3-48ac-815b-002fcffc58c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a96da10-9392-472d-9cee-126cade7eaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30da04c7-19f3-4626-afd0-627a77241484",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Fixing backward implementation - TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "102d8194-1eed-482f-823d-4b12a87488ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_recurrent_rwkv6_bwd_hypnofix(q, k, v, w, u, o, do, initial_state=None, output_final_state=False):\n",
    "    q, k, v, w, u, o, do = map(lambda x: x.float(), (q, k, v, w, u, o, do))\n",
    "    batch_size, n_heads, seq_len, d_head_k = q.shape\n",
    "    _, _, _, d_head_v = v.shape\n",
    "    h = torch.zeros(batch_size, n_heads, d_head_k, d_head_v, dtype=torch.float32, device=q.device)\n",
    "    dq = torch.zeros_like(q)\n",
    "    dq_aux = torch.zeros_like(q)\n",
    "\n",
    "    if initial_state is not None:\n",
    "        h += initial_state\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        k_i = k[:, :, i]\n",
    "        v_i = v[:, :, i]\n",
    "        w_i = w[:, :, i].exp()\n",
    "        do_i = do[:, :, i]\n",
    "        kv_i = k_i[..., None] * v_i[..., None, :]\n",
    "        dq[:, :, i] = ((h * + kv_i * u[None, ..., None]) * do_i[None, :]).sum(dim=-1)\n",
    "        dq_aux[:, :, i] = (h * do_i[None, :]).sum(-1)\n",
    "        h = h * w_i[..., None] + kv_i\n",
    "        \n",
    "    du = u.new_zeros(batch_size, n_heads, d_head_k)\n",
    "    dh = torch.zeros_like(h)\n",
    "    dk = torch.zeros_like(k)\n",
    "    dk_aux = torch.zeros_like(k)\n",
    "    dv = torch.zeros_like(v)\n",
    "\n",
    "    for i in range(seq_len-1, -1, -1):\n",
    "        d_kv_i = do[:, :, i, None, :] * q[:, :, i, :, None]\n",
    "        k_i = k[:, :, i]\n",
    "        v_i = v[:, :, i]\n",
    "        du_i = (d_kv_i * k_i[..., None] * v_i[..., None, :]).sum(-1)\n",
    "        du += du_i\n",
    "        dk_aux[:, :, i] = (dh * v_i[..., None, :]).sum(-1)\n",
    "        \n",
    "        d_kv_hiu = (dh + d_kv_i * u[None, ..., None])\n",
    "        dk[:, :, i] = (d_kv_hiu * v_i[..., None, :]).sum(-1)\n",
    "        dv[:, :, i] = (d_kv_hiu * k_i[..., :, None]).sum(-2)\n",
    "\n",
    "        # dk_aux[:, :, i] = (dh * v_i[..., None, :] * k_i[..., None]).sum(-1)\n",
    "        dh = dh * w[:, :, i, :, None].exp() + d_kv_i\n",
    "\n",
    "    # dw = q * dq_aux - k * dk_aux\n",
    "    # dw = torch.zeros_like(w)\n",
    "    #for i in range(seq_len-2, -1, -1):\n",
    "    #    dw[:, :, i] = dw[:, :, i+1] + dq_aux[:, :, i+1] * q[:, :, i+1] - dk_aux[:, :, i] * k[:, :, i]\n",
    "    dw = (dq_aux * q)[:, :, 1:, ...] - (dk_aux * k)[:, :, 0:-1]\n",
    "    dw = torch.nn.functional.pad(dw, (0, 0, 0, 1, 0, 0, 0, 0), value=0)\n",
    "    dw = dw.flip([-2,]).cumsum(dim=-2).flip([-2,])\n",
    "    \n",
    "    du = du.sum(0)\n",
    "    return dq, dk, dv, dw, du"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a6ef4b0-2abd-4142-ae31-08eb94406d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-7.5242e-09, -7.5242e-09,  4.1360e-06,  2.2635e-06, -1.5978e-04,\n",
       "         -4.1195e-05, -1.8432e-04, -1.2256e-04, -1.7147e-03, -4.5438e-04,\n",
       "          5.7485e-03,  2.3668e-03,  3.1560e-04,  2.0305e-04, -8.2964e-05,\n",
       "         -1.6727e-05, -1.6277e-04, -6.2998e-05, -2.8594e-04, -1.8627e-04,\n",
       "          1.9118e-02,  1.0362e-02,  2.5464e-02,  1.5361e-02, -3.9735e-03,\n",
       "         -1.9676e-03, -1.7708e-03, -5.4920e-04,  4.4832e-07,  3.1956e-08,\n",
       "         -0.0000e+00, -0.0000e+00]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([-7.5242e-09, -7.5242e-09,  2.2635e-06,  2.2635e-06, -4.1195e-05,\n",
       "         -4.1195e-05, -1.2256e-04, -1.2256e-04, -4.5438e-04, -4.5438e-04,\n",
       "          2.3668e-03,  2.3668e-03,  2.0305e-04,  2.0305e-04, -1.6727e-05,\n",
       "         -1.6727e-05, -6.2998e-05, -6.2998e-05, -1.8627e-04, -1.8627e-04,\n",
       "          1.0362e-02,  1.0362e-02,  1.5361e-02,  1.5361e-02, -1.9676e-03,\n",
       "         -1.9676e-03, -5.4920e-04, -5.4920e-04,  3.1956e-08,  3.1956e-08,\n",
       "         -0.0000e+00, -0.0000e+00]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implementation is wrong. hidden by high V (ex. 64)\n",
    "B, H, L, K, V = 1, 1, 16, 1, 2\n",
    "\n",
    "#### AUTOGRAD FORWARD PASS\n",
    "rt, kt, vt, wt, ut = gen_inputs(B, H, L, K, V)\n",
    "w_ = -th.exp(wt)\n",
    "o = naive_recurrent_rwkv6_original(rt, kt, vt, w_[..., 0], ut[..., 0])\n",
    "grads = []\n",
    "o.register_hook(lambda d:grads.append(d))\n",
    "o.mean().backward()\n",
    "do = grads[0]\n",
    "\n",
    "#### Autograd rwkv_inner\n",
    "rt3, kt3, vt3, wt3, ut3 = gen_inputs(B, H, L, K, V)\n",
    "w3_ = -th.exp(wt3)\n",
    "o3, state3 = rwkv_inner(rt3, kt3, vt3, w3_[..., 0], ut3.view(1, H, 1, K), th.zeros(B, H, K, V))\n",
    "o3.mean().backward()\n",
    "\n",
    "#### MANUAL BACKWARD PASS\n",
    "rt2, kt2, vt2, wt2, ut2 = gen_inputs(B, H, L, K, V)\n",
    "w2_ = -th.exp(wt2)\n",
    "dq, dk, dv, dw, du = naive_recurrent_rwkv6_bwd_hypnofix(rt2, kt2, vt2, w2_[..., 0], ut2[..., 0], o, do)\n",
    "dw = dw[..., None]\n",
    "(wt.grad - dw).detach().flatten(), (w_ - w2_).detach().flatten(), (wt3.grad - dw).detach().flatten(), (w3_ - w2_).detach().flatten()\n",
    "\n",
    "#### DOESN'T MATCH!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b5e4b-ba22-4144-b80a-25752e0bb717",
   "metadata": {},
   "source": [
    "#### My funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da08269a-4af5-4474-a702-9e972fbf7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_recurrent_rwkv6(q, k, v, w, u, initial_state=None, output_final_state=False):\n",
    "    orig_dtype = q.dtype\n",
    "    q, k, v, w, u = map(lambda x: x.float(), (q, k, v, w, u))\n",
    "    batch_size, n_heads, seq_len, d_head_k = q.shape\n",
    "    _, _, _, d_head_v = v.shape\n",
    "    h = torch.zeros(batch_size, n_heads, d_head_k, d_head_v, dtype=torch.float32, device=q.device)\n",
    "    o = torch.zeros_like(v)\n",
    "\n",
    "    if initial_state is not None:\n",
    "        h += initial_state\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        q_i = q[:, :, i, :]\n",
    "        k_i = k[:, :, i]\n",
    "        v_i = v[:, :, i, :]\n",
    "        w_i = w[:, :, i].exp()\n",
    "        kv_i = k_i[..., None] * v_i[..., None, :]\n",
    "        # print(f\"h.shape: {h.shape}, u.shape: {u[None, ..., None].shape} and kv.shape: {kv_i.shape}\")\n",
    "        h_i = (h + u[None, ..., None] * kv_i)\n",
    "        o_i = th.einsum('bhc,bhcd->bhd', q_i, h_i)\n",
    "        o[:, :, i] = o_i.sum(-2)\n",
    "        h = h * w_i + kv_i\n",
    "    return o.to(orig_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aff4ca3-785a-4436-bb62-4279b25f2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_recurrent_rwkv6_bwd(q, k, v, w, u, o, do, initial_state=None, output_final_state=False):\n",
    "    q, k, v, w, u, o, do = map(lambda x: x.float(), (q, k, v, w, u, o, do))\n",
    "    batch_size, n_heads, seq_len, d_head_k = q.shape\n",
    "    _, _, _, d_head_v = v.shape\n",
    "    h = torch.zeros(batch_size, n_heads, d_head_k, d_head_v, dtype=torch.float32, device=q.device)\n",
    "    dq = torch.zeros_like(q)\n",
    "    dq_aux = torch.zeros_like(q)\n",
    "\n",
    "    if initial_state is not None:\n",
    "        h += initial_state\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        k_i = k[:, :, i]\n",
    "        v_i = v[:, :, i]\n",
    "        w_i = w[:, :, i].exp()\n",
    "        kv_i = k_i[..., None] * v_i[..., None, :]\n",
    "        h_i = (h + u[None, ..., None] * kv_i)\n",
    "        dq_i = (do[:, :, i, None, :] * h_i).sum(-1)\n",
    "        dq_aux_i = (do[:, :, i, None, :] * h).sum(-1)\n",
    "        dq[:, :, i] = dq_i\n",
    "        dq_aux[:, :, i] = dq_aux_i\n",
    "        h = h * w_i + kv_i\n",
    "\n",
    "    du = torch.zeros(batch_size, n_heads, d_head_k)\n",
    "    dh = torch.zeros_like(h)\n",
    "    dk = torch.zeros_like(k)\n",
    "    dk_aux = torch.zeros_like(k)\n",
    "    dv = torch.zeros_like(v)\n",
    "\n",
    "    for i in range(seq_len-1, -1, -1):\n",
    "        d_kv_i = do[:, :, i, None, :] * q[:, :, i, :, None]\n",
    "        k_i = k[:, :, i]\n",
    "        v_i = v[:, :, i]\n",
    "        du_i = (d_kv_i * k_i[..., None] * v_i[..., None, :]).sum(-1)\n",
    "        du += du_i\n",
    "        dk_i = (dh * v_i[..., None, :]).sum(-1)\n",
    "        dk_aux[:, :, i] = dk_i\n",
    "        dk_i += (d_kv_i * u[None, ..., None] * v_i[..., None, :]).sum(-1)\n",
    "        dv_i = (d_kv_i * u[None, ..., None] * k_i[..., None]).sum(-2)\n",
    "        dv_i += (dh * k_i[..., None]).sum(-2)\n",
    "\n",
    "        dk[:, :, i] = dk_i\n",
    "        dv[:, :, i] = dv_i\n",
    "        dh = dh * w[:, :, i, :, :].exp() + d_kv_i\n",
    "\n",
    "    # dw = q * dq_aux - k * dk_aux\n",
    "    dw = torch.zeros_like(w)\n",
    "    for i in range(seq_len-2, -1, -1):\n",
    "        dw[:, :, i] = dw[:, :, i+1] + (dq_aux[:, :, i+1] * q[:, :, i+1] - dk_aux[:, :, i] * k[:, :, i])[..., None]\n",
    "\n",
    "    du = du.sum(0)\n",
    "    return dq, dk, dv, dw, du"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce6d0a2-450f-46dc-834e-362b2f4878d9",
   "metadata": {},
   "source": [
    "#### My tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071dec21-b5b4-4fd1-be61-3735be79e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, H, L, K, V = 1, 1, 8, 1, 1\n",
    "\n",
    "#### AUTOGRAD FORWARD PASS\n",
    "rt, kt, vt, wt, ut = gen_inputs(B, H, L, K, V)\n",
    "w_ = -th.exp(wt)\n",
    "o = naive_recurrent_rwkv6(rt, kt, vt, w_, ut)\n",
    "# get grad of nonleaf variable\n",
    "grads = []\n",
    "o.register_hook(lambda d:grads.append(d))\n",
    "o.mean().backward()\n",
    "\n",
    "#### MANUAL BACKWARD PASS\n",
    "do = grads[0]\n",
    "rt2, kt2, vt2, wt2, ut2 = gen_inputs()\n",
    "w_ = -th.exp(wt2)\n",
    "dq, dk, dv, dw, du = naive_recurrent_rwkv6_bwd(rt2, kt2, vt2, w_, ut2, o, do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b24464-9b4f-48e6-a5e5-1a4c0cf5cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt.grad - dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b594a71-8015-46a2-8fd9-500b88e380b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada1047-1a2c-4e5d-99ee-7906dc8ff54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e7da12-d674-4b21-a3d7-19718cc274f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceafdc6c-2f2e-4d1a-a66f-4fce5a0f46be",
   "metadata": {},
   "outputs": [],
   "source": [
    "(rt.grad - dq).flatten(), (kt.grad - dk).flatten(), (vt.grad - dv).flatten(), (ut.grad - du).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcff9fc5-054a-4217-8f4c-fe70cc81198b",
   "metadata": {},
   "source": [
    "## AOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43b370-f6da-4f13-88ed-9b2a4a540723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa51c30-bc1b-48fa-8a17-2e8f5cd3dd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05f830-fa09-4ff7-930e-6086e356df1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac610e32-6322-4f9b-a585-f16c0662b234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ada7c-e8c3-4574-8b61-710697c6797e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
